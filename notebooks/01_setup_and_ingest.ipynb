{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81cf5caf",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #ccc; border-radius: 12px; padding: 20px; max-width: 950px; margin: auto; background-color: #1e1e1e; color: #f0f0f0; font-family: Arial, sans-serif; line-height: 1.6;\">\n",
    "\n",
    "  <div style=\"text-align: center; margin-bottom: 20px;\">\n",
    "    <img src=\"..\\images\\SlideHunter_Logo.png\" \n",
    "         alt=\"Coffee Production Boxplot by Subdivision\"\n",
    "         style=\"width: 80%; max-width: 80%; height: auto; border-radius: 8px; box-shadow: 0 0 10px rgba(0,0,0,0.4);\">\n",
    "  </div>\n",
    "\n",
    "  <blockquote style=\"margin: 0; padding: 10px 20px; border-left: 4px solid #4faaff;\">\n",
    "    <p><strong>\n",
    "      SlideHunter App\n",
    "    </strong></p>\n",
    "    <p>\n",
    "     User Interface (UI) : \n",
    "      <a href=\"..\\images\\SlideHunter_Logo.png\" target=\"_blank\" style=\"color: #4faaff;\">\n",
    "        Find exactly where a topic was covered in course materials. Fast answers with precise slide/page citations.\n",
    "      </a>\n",
    "    </p>\n",
    "  </blockquote>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6bfa35",
   "metadata": {},
   "source": [
    "# 01 â€” Setup & Ingest\n",
    "This notebook parses PDFs (page-level), embeds chunks, and builds a FAISS Store\n",
    "\n",
    "## Install (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04fbd047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning surpresser\n",
    "import os\n",
    "\n",
    "# Tell Hugging Face to skip TensorFlow/Flax so they never import TensorFlow (TF).\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_NO_FLAX\"] = \"1\"\n",
    "\n",
    "# Quiet TF logs if something still pulls it in.\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # 1=INFO, 2=WARNING, 3=ERROR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "959f56d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# OPTIONAL If env is missing packages\n",
    "%pip install -q sentence-transformers faiss-cpu beautifulsoup4 canvasapi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bf7782",
   "metadata": {},
   "source": [
    "## Imports and Crendentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3c2be23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from canvasapi import Canvas\n",
    "from bs4 import BeautifulSoup\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np, faiss, re, json, os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce1c3f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CANVAS_BASE_UR = \"add here\" \n",
    "#CANVAS_TOKEN = \"add here\"\n",
    "\n",
    "CANVAS_BASE_URL=\"https://tkh.instructure.com\" \n",
    "CANVAS_TOKEN=\"23885~ZaCTh63JmTHamHWMAxBtWUQQxUuRWGm4kNfMHJKhBcvnU44mw9vND4eaXEPLGDvk\"\n",
    "\n",
    "canvas = Canvas(CANVAS_BASE_URL, CANVAS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "963e5605",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_courses = canvas.get_courses()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a85877e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foundations '25 Data Science\n",
      "Foundations Course\n",
      "IF '25 Data Science Cohort A\n",
      "IF '25 NY Career Readiness and Success\n"
     ]
    }
   ],
   "source": [
    "my_courses = canvas.get_courses()\n",
    "course_list = []\n",
    "\n",
    "for course in my_courses:\n",
    "    print(course.name)\n",
    "    course_list.append(course)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0df8d2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Module_id: 1118\n",
      "  Module: Fellow Resources\n",
      " - Item: Fellow Success Resources (Page)\n",
      "  Module_id: 1239\n",
      "  Module: Phase 2 (6/9-8/29)\n",
      " - Item: Homework: Option 1 - Weekly Job Applications & Progress Report (Due August 30) (Assignment)\n",
      " - Item: P2W1 (6/12) NO CAREER CLASS - TECHNICAL CLASS (SubHeader)\n",
      " - Item: P2W2 (6/16) Bloomberg Ideathon (SubHeader)\n",
      " - Item: Homework (SubHeader)\n",
      " - Item: Homework: Watch Hackathon Video (Assignment)\n",
      " - Item: Homework: Upwardly Global Learning Paths: Tech Market/Resume/Cover Letter (Assignment)\n",
      " - Item: Homework: Draft Resume (Assignment)\n",
      " - Item: P2W2 NO CLASS MEETING 6/19 Juneteenth TKH Closed (SubHeader)\n",
      " - Item: P2W3 (6/26) Bloomberg Hackathon (SubHeader)\n",
      " - Item: Homework (SubHeader)\n",
      " - Item: Homework: Hackathon Activity Log + Judges' Feedback (Assignment)\n",
      " - Item: P2W4 (7/3) Resume + Digital Footprint (SubHeader)\n",
      " - Item: In Class Activity (SubHeader)\n",
      " - Item: In-Class Activity: Updated Resume (Assignment)\n",
      " - Item: Homework (SubHeader)\n",
      " - Item: Homework: Upwardly Global Learning Path: Marketing Yourself (Assignment)\n",
      " - Item: Homework: LinkedIn Profile (Assignment)\n",
      " - Item: Grades due by 7/7 [note for staff] (SubHeader)\n",
      " - Item:  P2W5 (7/10) Elevator Pitch + \"Tell Me About Yourself\" (SubHeader)\n",
      " - Item: Homework (SubHeader)\n",
      " - Item: Homework: Elevator Pitch Video (Assignment)\n",
      " - Item: Homework: Upwardly Global Learning Path: Networking (Assignment)\n",
      " - Item: P2W6 (7/17) Company Exposure (SubHeader)\n",
      " - Item: P2W7 (7/24) Career Exploration + Job Search (SubHeader)\n",
      " - Item: In Class Activity (SubHeader)\n",
      " - Item: In-Class Activity: Career Plan (Assignment)\n",
      " - Item: Homework (SubHeader)\n",
      " - Item: Homework: Weekly Job Applications & Networking (Due July 26) (Assignment)\n",
      " - Item: Prepare for next week's speed networking session. (SubHeader)\n",
      " - Item:  P2W8 (7/31) Speed Networking (SubHeader)\n",
      " - Item: Homework (SubHeader)\n",
      " - Item: (OPTIONAL) Homework: Weekly Job Applications & Networking (Due August 2) (Assignment)\n",
      " - Item: Homework: Upwardly Global Learning Path: Interview (Assignment)\n",
      " - Item: Grades due by 8/4 [note for staff] (SubHeader)\n",
      " - Item: P2W9 (8/7) SWOT + Confidence Gap (SubHeader)\n",
      " - Item: Career Class Option Selection (Due August 9) (Quiz)\n",
      " - Item: In Class Activity (SubHeader)\n",
      " - Item: Homework (SubHeader)\n",
      " - Item: P2W10 (8/14) Applications Questions + Behavioral Interviews (SubHeader)\n",
      " - Item: In Class Activity (SubHeader)\n",
      " - Item: In-Class Activity: Application Questions (Assignment)\n",
      " - Item: Homework (SubHeader)\n",
      " - Item: Homework: Option 1 - Weekly Job Applications & Progress Report (Due August 23) (Assignment)\n",
      " - Item: Prepare for mock behavioral interviews that will take place next week. (SubHeader)\n",
      " - Item: P2W11 (8/21) Behavioral Mock Interviews (SubHeader)\n",
      " - Item: Homework (SubHeader)\n",
      " - Item: Homework: Option 1 - Weekly Job Applications & Progress Report (Due August 30) (Assignment)\n",
      " - Item: P2W12 (8/28) Portfolio Storytelling (Last Week of Phase 2) (SubHeader)\n",
      " - Item: Homework (SubHeader)\n",
      " - Item: Homework: Portfolio (Assignment)\n",
      " - Item: Grades due by 9/2 [note for staff] (SubHeader)\n",
      "  Module_id: 1222\n",
      "  Module: Monthly Program Satisfaction Surveys\n",
      " - Item: March Program Satisfaction (Assignment)\n",
      " - Item: April Program Satisfaction  (Assignment)\n",
      " - Item: May Program Satisfaction (Assignment)\n",
      " - Item: June Program Satisfaction  (Assignment)\n",
      " - Item: July Program Satisfaction (Assignment)\n",
      " - Item: August Program Satisfaction  (Assignment)\n",
      " - Item: September Program Satisfaction (Assignment)\n",
      " - Item: October Program Satisfaction  (Assignment)\n",
      " - Item: November Program Satisfaction  (Assignment)\n"
     ]
    }
   ],
   "source": [
    "modules = course.get_modules()\n",
    "\n",
    "for module in modules:\n",
    "    print(f\"  Module_id: {module.id}\")\n",
    "    print(f\"  Module: {module.name}\")\n",
    "    module_items = module.get_module_items()\n",
    "    for item in module_items:\n",
    "        print(f\" - Item: {item.title} ({item.type})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d73e785",
   "metadata": {},
   "source": [
    "## Embedding Tokenized Canvas modules (Texts/items). Then Turning Those Embddings into a facts list + FAISS index that we can query.\n",
    "\n",
    "1. Build facts (+ metadata) from Canvas\n",
    "  - This pulls Pages' text (HTML â†’ plain text), and adds light facts for  \n",
    "    External URLs / Files / SubHeaders â†’ may have to extend later.\n",
    "\n",
    "## single FAISS store:\n",
    "- Simple/Demo MVP, which tags every fact with a domain and use a tiny auto-router\n",
    "  - Two-way short route descriptions (technical.index and career.index)\n",
    "    - Pulls multiple Canvas courses\n",
    "    - Builds one facts/metas list with domain in metadata\n",
    "    - And creates one FAISS index\n",
    "- This method routes queries to technical / career / all--automatically and filters hits accordingly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6a73a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-course to ONE FAISS store + simple router using career and technical courses\n",
    "\n",
    "# 0) CONFIG: map course names to domain buckets\n",
    "DOMAINS = {\n",
    "    \"technical\": [\n",
    "        \"Foundations '25 Data Science\",\n",
    "        \"Foundations Course\",\n",
    "        \"IF '25 Data Science Cohort A\",\n",
    "    ],\n",
    "    \"career\": [\n",
    "        \"IF '25 NY Career Readiness and Success\",\n",
    "    ],\n",
    "}\n",
    "# Short route descriptions--We can add more if needed (used for auto routing purpos)\n",
    "ROUTE_DESC = {\n",
    "    \"technical\": \"Technical class content: Python, SQL, statistics, machine learning, slides, labs, code, algorithms, data science, lecture notes.\",\n",
    "    \"career\":    \"Career readiness content: resumes, cover letters, job search, interviews, career prep, LinkedIn, networking, internship resources.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "70860845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Utility: HTML â†’ text, light chunking\n",
    "def strip_html(html: str) -> str:\n",
    "    if not html: return \"\"\n",
    "    txt = \" \".join(BeautifulSoup(html, \"html.parser\").stripped_strings)\n",
    "    return re.sub(r\"\\s+\", \" \", txt).strip()\n",
    "\n",
    "def chunk_text(text, max_chars=600):\n",
    "    if not text: return []\n",
    "    parts = re.split(r\"(\\n|\\.\\s+)\", text)\n",
    "    buf, chunks = \"\", []\n",
    "    for p in parts:\n",
    "        buf += p\n",
    "        if len(buf) >= max_chars:\n",
    "            chunks.append(buf.strip()); buf = \"\"\n",
    "    if buf.strip(): chunks.append(buf.strip())\n",
    "    return [c for c in chunks if c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "57b6c730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected courses: [\"Foundations '25 Data Science\", 'Foundations Course', \"IF '25 Data Science Cohort A\", \"IF '25 NY Career Readiness and Success\"]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2) Select courses by name (use your Canvas client `canvas`)\n",
    "def course_domain(course_name: str):\n",
    "    for dom, names in DOMAINS.items():\n",
    "        if any(course_name.startswith(n) for n in names):\n",
    "            return dom\n",
    "    return \"other\"\n",
    "\n",
    "wanted_prefixes = sum(DOMAINS.values(), [])\n",
    "all_courses = [c for c in canvas.get_courses(enrollment_state=\"active\")\n",
    "               if any(c.name.startswith(p) for p in wanted_prefixes)]\n",
    "\n",
    "print(\"Selected courses:\", [c.name for c in all_courses])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c577dd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 323 facts\n"
     ]
    }
   ],
   "source": [
    "# 3) Build facts + metas from ALL selected courses\n",
    "facts, metas = [], []\n",
    "for crs in all_courses:\n",
    "    dom = course_domain(crs.name)\n",
    "    for module in crs.get_modules():\n",
    "        for item in module.get_module_items():\n",
    "            t = (item.type or \"\").strip()\n",
    "            if t == \"Page\":\n",
    "                page = crs.get_page(item.page_url)\n",
    "                text = strip_html(getattr(page, \"body\", \"\"))\n",
    "                for chunk in chunk_text(text, max_chars=600):\n",
    "                    facts.append(f\"[{dom}] {crs.name} â€º {module.name} â€º {item.title}: {chunk}\")\n",
    "                    metas.append({\n",
    "                        \"domain\": dom,\n",
    "                        \"course_id\": crs.id, \"course_name\": crs.name,\n",
    "                        \"module_id\": module.id, \"module_name\": module.name,\n",
    "                        \"item_title\": item.title, \"type\": \"Page\",\n",
    "                        \"url\": getattr(page, \"html_url\", None)\n",
    "                    })\n",
    "            elif t in (\"ExternalUrl\", \"ExternalTool\"):\n",
    "                facts.append(f\"[{dom}] {crs.name} â€º {module.name} â€º {item.title}: external link {getattr(item, 'external_url', '')}\")\n",
    "                metas.append({\n",
    "                    \"domain\": dom, \"course_id\": crs.id, \"course_name\": crs.name,\n",
    "                    \"module_id\": module.id, \"module_name\": module.name,\n",
    "                    \"item_title\": item.title, \"type\": t,\n",
    "                    \"url\": getattr(item, \"external_url\", None)\n",
    "                })\n",
    "            elif t == \"File\":\n",
    "                facts.append(f\"[{dom}] {crs.name} â€º {module.name} â€º {item.title} (file)\")\n",
    "                metas.append({\n",
    "                    \"domain\": dom, \"course_id\": crs.id, \"course_name\": crs.name,\n",
    "                    \"module_id\": module.id, \"module_name\": module.name,\n",
    "                    \"item_title\": item.title, \"type\": \"File\", \"file_id\": item.content_id\n",
    "                })\n",
    "            elif t == \"SubHeader\":\n",
    "                continue\n",
    "            else:\n",
    "                facts.append(f\"[{dom}] {crs.name} â€º {module.name} â€º {item.title} ({t})\")\n",
    "                metas.append({\n",
    "                    \"domain\": dom, \"course_id\": crs.id, \"course_name\": crs.name,\n",
    "                    \"module_id\": module.id, \"module_name\": module.name,\n",
    "                    \"item_title\": item.title, \"type\": t\n",
    "                })\n",
    "\n",
    "print(f\"Built {len(facts)} facts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "978e64bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8667f3587a114cbdbece1a45c1417aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS ntotal: 323\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4) Embed â€” use GPU if available, else CPU\n",
    "import torch\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=DEVICE)\n",
    "print(\"model device:\", model.device)\n",
    "\n",
    "# (optional) quick warm-up on GPU\n",
    "if DEVICE == \"cuda\":\n",
    "    _ = model.encode([\"warm up\"], show_progress_bar=False)\n",
    "\n",
    "# pick a sensible batch size per device\n",
    "BATCH = 192 if DEVICE == \"cuda\" else 64\n",
    "\n",
    "emb = model.encode(\n",
    "    facts,\n",
    "    batch_size=BATCH,\n",
    "    normalize_embeddings=True,   # cosine-ready\n",
    "    convert_to_numpy=True,       # returns NumPy on CPU for FAISS\n",
    "    show_progress_bar=True\n",
    ").astype(\"float32\")\n",
    "\n",
    "d = emb.shape[1]\n",
    "index = faiss.IndexFlatIP(d)               # cosine (vectors normalized)\n",
    "index.add(emb)\n",
    "print(\"FAISS ntotal:\", index.ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "35519bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Router: choose technical / career / all based on similarity to route descriptions\n",
    "route_emb = {k: model.encode([v], normalize_embeddings=True).astype(\"float32\") for k,v in ROUTE_DESC.items()}\n",
    "\n",
    "def choose_scope(query, margin=0.05):\n",
    "    q = model.encode([query], normalize_embeddings=True).astype(\"float32\")\n",
    "    sims = {k: float((q @ route_emb[k].T)[0,0]) for k in ROUTE_DESC}\n",
    "    best = max(sims, key=sims.get)\n",
    "    # if not clearly better, use 'all'\n",
    "    ordered = sorted(sims.items(), key=lambda x: x[1], reverse=True)\n",
    "    if ordered[0][1] - ordered[1][1] < margin:\n",
    "        return \"all\", sims\n",
    "    return best, sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f749f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Search with optional scope filter (auto by default)\n",
    "def search(query, k=5, scope=\"auto\"):\n",
    "    if scope == \"auto\":\n",
    "        scope, sims = choose_scope(query)\n",
    "    q = model.encode([query], normalize_embeddings=True).astype(\"float32\")\n",
    "    # pull more then filter by domain\n",
    "    D, I = index.search(q, k*8)\n",
    "    hits = []\n",
    "    for score, idx in zip(D[0], I[0]):\n",
    "        if idx == -1: continue\n",
    "        m = metas[idx]\n",
    "        if scope != \"all\" and m[\"domain\"] != scope:\n",
    "            continue\n",
    "        hits.append({\"score\": float(score), \"fact\": facts[idx], \"meta\": m})\n",
    "        if len(hits) >= k: break\n",
    "    # if not enough in-scope, backfill with any\n",
    "    if len(hits) < k:\n",
    "        for score, idx in zip(D[0], I[0]):\n",
    "            if idx == -1: continue\n",
    "            if any(h[\"meta\"] is metas[idx] for h in hits): continue\n",
    "            hits.append({\"score\": float(score), \"fact\": facts[idx], \"meta\": metas[idx]})\n",
    "            if len(hits) >= k: break\n",
    "    return scope, hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b9f0c513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: Where did we define precision vs. recall?   [scope=technical]\n",
      "  0.393 :: IF '25 Data Science Cohort A â€º P2W3 (6/23-6/27) Classification Algorithms â€º ðŸ’» W3D2 (6/24) Logistic Regression Accuracy Metrics (Page)  [https://tkh.instructure.com/courses/172/pages/w3d2-6-slash-24-logistic-regression-accuracy-metrics]\n",
      "  0.320 :: Foundations '25 Data Science â€º Week 5:  Statistics(Feb. 24th- Feb. 27th) â€º What is Data Science? (Page)  [https://tkh.instructure.com/courses/165/pages/what-is-data-science]\n",
      "  0.299 :: IF '25 Data Science Cohort A â€º P2W11 (8/18-8/22) Agents & End of Phase Project â€º ðŸ’» W11D1 (8/18) Applied LLM Review & AI Agents (Page)  [https://tkh.instructure.com/courses/172/pages/w11d1-8-slash-18-applied-llm-review-and-ai-agents]\n",
      "  0.279 :: Foundations '25 Data Science â€º Week 5:  Statistics(Feb. 24th- Feb. 27th) â€º What is Data Science? (Page)  [https://tkh.instructure.com/courses/165/pages/what-is-data-science]\n",
      "\n",
      "Q: tips for a resume and cover letter?   [scope=career]\n",
      "  0.402 :: IF '25 NY Career Readiness and Success â€º Phase 2 (6/9-8/29) â€º Homework: Draft Resume (Assignment)\n",
      "  0.398 :: IF '25 NY Career Readiness and Success â€º Phase 2 (6/9-8/29) â€º Homework: Upwardly Global Learning Paths: Tech Market/Resume/Cover Letter (Assignment)\n",
      "  0.343 :: IF '25 NY Career Readiness and Success â€º Phase 2 (6/9-8/29) â€º Homework: LinkedIn Profile (Assignment)\n",
      "  0.332 :: IF '25 NY Career Readiness and Success â€º Phase 2 (6/9-8/29) â€º Homework: Upwardly Global Learning Path: Marketing Yourself (Assignment)\n",
      "\n",
      "Q: What lecture slides did we learn about control flow?   [scope=technical]\n",
      "  0.394 :: Foundations Course â€º Week 1: Foundations For Success (Jan. 27th-Jan. 30th) â€º W1D2: Learning How to Learn (Page)  [https://tkh.instructure.com/courses/162/pages/w1d2-learning-how-to-learn]\n",
      "  0.346 :: Foundations Course â€º Week 3: Tech Essentials (Feb. 10th- Feb 13th) â€º Week 3 Overview  (Page)  [https://tkh.instructure.com/courses/162/pages/week-3-overview]\n",
      "  0.330 :: Foundations Course â€º Week 2: Charting Your Path (Feb. 3rd- Feb 6th) â€º W2D3: Track Exploration (Track Mini LessonsÂ Continued) (Page)  [https://tkh.instructure.com/courses/162/pages/w2d3-track-exploration-track-mini-lessons-continued]\n",
      "  0.323 :: Foundations Course â€º Week 3: Tech Essentials (Feb. 10th- Feb 13th) â€º Week 3 Overview  (Page)  [https://tkh.instructure.com/courses/162/pages/week-3-overview]\n"
     ]
    }
   ],
   "source": [
    "# 7) Try it out with some pre-test test-prompts\n",
    "tests = [\n",
    "    \"Where did we define precision vs. recall?\",\n",
    "    \"tips for a resume and cover letter?\",\n",
    "    \"What lecture slides did we learn about control flow?\",\n",
    "  ]\n",
    "for q in tests:\n",
    "    scope, hits = search(q, k=4, scope=\"auto\")\n",
    "    print(f\"\\nQ: {q}   [scope={scope}]\")\n",
    "    if not hits: print(\"  (no hits)\"); continue\n",
    "    for h in hits:\n",
    "        m = h[\"meta\"]\n",
    "        cite = f\"{m['course_name']} â€º {m['module_name']} â€º {m['item_title']} ({m['type']})\"\n",
    "        if m.get(\"url\"): cite += f\"  [{m['url']}]\"\n",
    "        print(f\"  {h['score']:.3f} :: {cite}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ca9519aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " saved: C:\\Users\\oneps\\Documents\\Research_Dev_Documents\\DataEden_Github\\TEPP-2-SlideHunt-Repo\\SlideHunt/data/faiss/canvas.index and C:\\Users\\oneps\\Documents\\Research_Dev_Documents\\DataEden_Github\\TEPP-2-SlideHunt-Repo\\SlideHunt/data/faiss/facts.json\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "\n",
    "os.makedirs(\"data/faiss\", exist_ok=True)\n",
    "faiss.write_index(index, \"data/faiss/canvas.index\")\n",
    "with open(\"data/faiss/facts.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"facts\": facts, \"metas\": metas}, f, ensure_ascii=False) # Persistence: save / load FAISS store + metadata\n",
    "import os, json, faiss\n",
    "from pathlib import Path\n",
    "\n",
    "STORE_DIR  = f\"{BASE}/data/faiss\"\n",
    "INDEX_PATH = f\"{STORE_DIR}/canvas.index\"\n",
    "FACTS_PATH = f\"{STORE_DIR}/facts.json\"\n",
    "\n",
    "def save_store(index, facts, metas, store_dir=STORE_DIR):\n",
    "    Path(store_dir).mkdir(parents=True, exist_ok=True)\n",
    "    faiss.write_index(index, os.path.join(store_dir, \"canvas.index\"))\n",
    "    with open(os.path.join(store_dir, \"facts.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"facts\": facts, \"metas\": metas}, f, ensure_ascii=False)\n",
    "    print(\" saved:\", INDEX_PATH, \"and\", FACTS_PATH)\n",
    "\n",
    "def load_store(store_dir=STORE_DIR):\n",
    "    idx = faiss.read_index(os.path.join(store_dir, \"canvas.index\"))\n",
    "    with open(os.path.join(store_dir, \"facts.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    print(\" loaded:\", os.path.join(store_dir, \"canvas.index\"), \"and facts.json\")\n",
    "    return idx, data[\"facts\"], data[\"metas\"]\n",
    "\n",
    "# This saves preceding index, facts, and metadata right after building\n",
    "save_store(index, facts, metas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
