{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81cf5caf",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #ccc; border-radius: 12px; padding: 20px; max-width: 950px; margin: auto; background-color: #1e1e1e; color: #f0f0f0; font-family: Arial, sans-serif; line-height: 1.6;\">\n",
    "\n",
    "  <div style=\"text-align: center; margin-bottom: 20px;\">\n",
    "    <img src=\"..\\images\\SlideHunter_Logo.png\" \n",
    "         alt=\"Coffee Production Boxplot by Subdivision\"\n",
    "         style=\"width: 80%; max-width: 80%; height: auto; border-radius: 8px; box-shadow: 0 0 10px rgba(0,0,0,0.4);\">\n",
    "  </div>\n",
    "\n",
    "  <blockquote style=\"margin: 0; padding: 10px 20px; border-left: 4px solid #4faaff;\">\n",
    "    <p><strong>\n",
    "      SlideHunter App\n",
    "    </strong></p>\n",
    "    <p>\n",
    "     User Interface (UI) : \n",
    "      <a href=\"..\\images\\SlideHunter_Logo.png\" target=\"_blank\" style=\"color: #4faaff;\">\n",
    "        Find exactly where a topic was covered in course materials. Fast answers with precise slide/page citations.\n",
    "      </a>\n",
    "    </p>\n",
    "  </blockquote>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95821ea5",
   "metadata": {},
   "source": [
    "## Check if GPU is alalable for faster embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ce45304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda_available: False\n",
      "torch.cuda: None\n",
      "device: CPU only\n"
     ]
    }
   ],
   "source": [
    "import torch, platform\n",
    "\n",
    "print(\"cuda_available:\", torch.cuda.is_available())\n",
    "print(\"torch.cuda:\", torch.version.cuda)          # None if CUDA isn't available\n",
    "print(\"device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU only\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6bfa35",
   "metadata": {},
   "source": [
    "# 01 â€” Setup & Ingest Notebook\n",
    "\n",
    "## Retrieval-Augmented-Generation (RAG)\n",
    "\n",
    "Retrieval-Augmented Generation is a *technique* to improve an LLM's responses by:\n",
    "* Retrieving relevant documents from a knowledge store (such FAISS or a vector DB).\n",
    "* Augmenting the model's prompt with those documents.\n",
    "* Generating an answer using the model with this extra context.\n",
    "\n",
    "With RAG, the model is handed the right documents at generation time. That is, the model does not respond to a user's queries until it refers to a specified set of documents.\n",
    "\n",
    "The FAISS store acts as our long-term memory for domain knowledge. The RAG pipeline serves as the reasoning loop: it retrieves the most relevant content, assembles the top results into a compact context, and passes that context to the LLM to produce a grounded, citeable response.\n",
    "- Think of FAISS as the library and RAG as the librarian: FAISS shelves all the course knowledge; RAG finds the right books, marks the key pages, and hands them to the model to explain.\n",
    "\n",
    "This notebook parses PDFs (page-level), embeds chunks, and builds a FAISS Store\n",
    "\n",
    "\n",
    "## Install (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04fbd047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning surpresser\n",
    "import os\n",
    "\n",
    "# Tell Hugging Face to skip TensorFlow/Flax so they never import TensorFlow (TF).\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_NO_FLAX\"] = \"1\"\n",
    "\n",
    "# Quiet TF logs if something still pulls it in.\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # 1=INFO, 2=WARNING, 3=ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c9353a",
   "metadata": {},
   "source": [
    "## Imports and Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "959f56d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL If env is missing packages\n",
    "#%pip install -q sentence-transformers faiss-cpu beautifulsoup4 canvasapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53230a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "from bs4 import BeautifulSoup\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np, faiss, re, json, os\n",
    "from canvasapi import Canvas\n",
    "import torch\n",
    "\n",
    "# Load environment variables from .env file\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3c2be23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "config = dotenv_values() # load .env file\n",
    "\n",
    "# Injest and process data from Canvas Sections\n",
    "# Set up Canva API client\n",
    "CANVAS_BASE_URL = config.get(\"CANVAS_BASE_URL\")\n",
    "CANVAS_TOKEN=config.get(\"CANVAS_TOKEN\")\n",
    "OPENAI_API_KEY = config.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize Canvas API client \n",
    "canvas = Canvas(CANVAS_BASE_URL, CANVAS_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad90c594",
   "metadata": {},
   "source": [
    "## Injest and process data from Canvas Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "963e5605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the list of courses\n",
    "my_courses = canvas.get_courses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a85877e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foundations '25 Data Science\n",
      "Foundations Course\n",
      "IF '25 Data Science Cohort A\n",
      "IF '25 NY Career Readiness and Success\n"
     ]
    }
   ],
   "source": [
    "# Pulling courses from Canvas\n",
    "my_courses = canvas.get_courses()\n",
    "course_list = []\n",
    "\n",
    "for course in my_courses:\n",
    "    print(course.name)\n",
    "    course_list.append(course)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0df8d2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Module_id: 1118\n",
      "  Module: Fellow Resources\n",
      " - Item: Fellow Success Resources (Page)\n",
      "  Module_id: 1239\n",
      "  Module: Phase 2 (6/9-8/29)\n",
      " - Item: Homework: Option 1 - Weekly Job Applications & Progress Report (Due August 30) (Assignment)\n",
      " - Item: P2W1 (6/12) NO CAREER CLASS - TECHNICAL CLASS (SubHeader)\n",
      " - Item: P2W2 (6/16) Bloomberg Ideathon (SubHeader)\n",
      " - Item: Homework (SubHeader)\n",
      " - Item: Homework: Watch Hackathon Video (Assignment)\n",
      " - Item: Homework: Upwardly Global Learning Paths: Tech Market/Resume/Cover Letter (Assignment)\n",
      " - Item: Homework: Draft Resume (Assignment)\n",
      " - Item: P2W2 NO CLASS MEETING 6/19 Juneteenth TKH Closed (SubHeader)\n",
      " - Item: P2W3 (6/26) Bloomberg Hackathon (SubHeader)\n",
      " - Item: Homework (SubHeader)\n",
      " - Item: Homework: Hackathon Activity Log + Judges' Feedback (Assignment)\n",
      " - Item: P2W4 (7/3) Resume + Digital Footprint (SubHeader)\n",
      " - Item: In Class Activity (SubHeader)\n",
      " - Item: In-Class Activity: Updated Resume (Assignment)\n",
      " - Item: Homework (SubHeader)\n",
      " - Item: Homework: Upwardly Global Learning Path: Marketing Yourself (Assignment)\n",
      " - Item: Homework: LinkedIn Profile (Assignment)\n",
      " - Item: Grades due by 7/7 [note for staff] (SubHeader)\n",
      " - Item:  P2W5 (7/10) Elevator Pitch + \"Tell Me About Yourself\" (SubHeader)\n",
      " - Item: Homework (SubHeader)\n",
      " - Item: Homework: Elevator Pitch Video (Assignment)\n",
      " - Item: Homework: Upwardly Global Learning Path: Networking (Assignment)\n",
      " - Item: P2W6 (7/17) Company Exposure (SubHeader)\n",
      " - Item: P2W7 (7/24) Career Exploration + Job Search (SubHeader)\n",
      " - Item: In Class Activity (SubHeader)\n",
      " - Item: In-Class Activity: Career Plan (Assignment)\n",
      " - Item: Homework (SubHeader)\n",
      " - Item: Homework: Weekly Job Applications & Networking (Due July 26) (Assignment)\n",
      " - Item: Prepare for next week's speed networking session. (SubHeader)\n",
      " - Item:  P2W8 (7/31) Speed Networking (SubHeader)\n",
      " - Item: Homework (SubHeader)\n",
      " - Item: (OPTIONAL) Homework: Weekly Job Applications & Networking (Due August 2) (Assignment)\n",
      " - Item: Homework: Upwardly Global Learning Path: Interview (Assignment)\n",
      " - Item: Grades due by 8/4 [note for staff] (SubHeader)\n",
      " - Item: P2W9 (8/7) SWOT + Confidence Gap (SubHeader)\n",
      " - Item: Career Class Option Selection (Due August 9) (Quiz)\n",
      " - Item: In Class Activity (SubHeader)\n",
      " - Item: Homework (SubHeader)\n",
      " - Item: P2W10 (8/14) Applications Questions + Behavioral Interviews (SubHeader)\n",
      " - Item: In Class Activity (SubHeader)\n",
      " - Item: In-Class Activity: Application Questions (Assignment)\n",
      " - Item: Homework (SubHeader)\n",
      " - Item: Homework: Option 1 - Weekly Job Applications & Progress Report (Due August 23) (Assignment)\n",
      " - Item: Prepare for mock behavioral interviews that will take place next week. (SubHeader)\n",
      " - Item: P2W11 (8/21) Behavioral Mock Interviews (SubHeader)\n",
      " - Item: Homework (SubHeader)\n",
      " - Item: Homework: Option 1 - Weekly Job Applications & Progress Report (Due August 30) (Assignment)\n",
      " - Item: P2W12 (8/28) Portfolio Storytelling (Last Week of Phase 2) (SubHeader)\n",
      " - Item: Homework (SubHeader)\n",
      " - Item: Homework: Portfolio (Assignment)\n",
      " - Item: Grades due by 9/2 [note for staff] (SubHeader)\n",
      "  Module_id: 1222\n",
      "  Module: Monthly Program Satisfaction Surveys\n",
      " - Item: March Program Satisfaction (Assignment)\n",
      " - Item: April Program Satisfaction  (Assignment)\n",
      " - Item: May Program Satisfaction (Assignment)\n",
      " - Item: June Program Satisfaction  (Assignment)\n",
      " - Item: July Program Satisfaction (Assignment)\n",
      " - Item: August Program Satisfaction  (Assignment)\n",
      " - Item: September Program Satisfaction (Assignment)\n",
      " - Item: October Program Satisfaction  (Assignment)\n",
      " - Item: November Program Satisfaction  (Assignment)\n"
     ]
    }
   ],
   "source": [
    "# Pulling modules from courses on Canvas \n",
    "modules = course.get_modules()\n",
    "\n",
    "for module in modules:\n",
    "    print(f\"  Module_id: {module.id}\")\n",
    "    print(f\"  Module: {module.name}\")\n",
    "    module_items = module.get_module_items()\n",
    "    for item in module_items:\n",
    "        print(f\" - Item: {item.title} ({item.type})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd6497b",
   "metadata": {},
   "source": [
    "## Embedding Tokenized Canvas modules (Texts/items). Then Turning Those Embddings into a facts list + FAISS index that we can query.\n",
    "\n",
    "1. Build facts (+ metadata) from Canvas\n",
    "  - This pulls Pages' text (HTML â†’ plain text), and adds light facts for  \n",
    "    External URLs / Files / SubHeaders â†’ we may have to extend this later.\n",
    "\n",
    "## single FAISS store:\n",
    "- Simple/Demo MVP, which tags every fact with a domain and use a tiny auto-router\n",
    "  - Two-way short route descriptions (technical.index and career.index)\n",
    "    - Pulls multiple Canvas courses\n",
    "    - Builds one facts/metas list with domain in metadata\n",
    "    - And creates one FAISS index\n",
    "- This method routes queries to technical / career / all--automatically and filters hits accordingly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d73e785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-course to ONE FAISS store + simple router using career and technical courses\n",
    "\n",
    "# 0) CONFIG: map course names to domain buckets\n",
    "\n",
    "DOMAINS = {\n",
    "    \"technical\": [\n",
    "        \"Foundations '25 Data Science\",\n",
    "        \"Foundations Course\",\n",
    "        \"IF '25 Data Science Cohort A\",\n",
    "    ],\n",
    "    \"career\": [\n",
    "        \"IF '25 NY Career Readiness and Success\",\n",
    "    ],\n",
    "}\n",
    "# Short route descriptions--We can add more if needed (used for auto routing purpos)\n",
    "ROUTE_DESC = {\n",
    "    \"technical\": \"Technical class content: Python, SQL, statistics, machine learning, slides, labs, code, algorithms, data science, lecture notes.\",\n",
    "    \"career\":    \"Career readiness content: resumes, cover letters, job search, interviews, career prep, LinkedIn, networking, internship resources.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fb4da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Utility: HTML â†’ text, light chunking\n",
    "def strip_html(html: str) -> str:\n",
    "    if not html: return \"\"\n",
    "    txt = \" \".join(BeautifulSoup(html, \"html.parser\").stripped_strings)\n",
    "    return re.sub(r\"\\s+\", \" \", txt).strip()\n",
    "\n",
    "def chunk_text(text, max_chars=600):\n",
    "    if not text: return []\n",
    "    parts = re.split(r\"(\\n|\\.\\s+)\", text)\n",
    "    buf, chunks = \"\", []\n",
    "    for p in parts:\n",
    "        buf += p\n",
    "        if len(buf) >= max_chars:\n",
    "            chunks.append(buf.strip()); buf = \"\"\n",
    "    if buf.strip(): chunks.append(buf.strip())\n",
    "    return [c for c in chunks if c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c1eb3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected courses: [\"Foundations '25 Data Science\", 'Foundations Course', \"IF '25 Data Science Cohort A\", \"IF '25 NY Career Readiness and Success\"]\n"
     ]
    }
   ],
   "source": [
    "# 2) Select courses by name (use your Canvas client `canvas`)\n",
    "\n",
    "def course_domain(course_name: str):\n",
    "    for dom, names in DOMAINS.items():\n",
    "        if any(course_name.startswith(n) for n in names):\n",
    "            return dom\n",
    "    return \"other\"\n",
    "\n",
    "wanted_prefixes = sum(DOMAINS.values(), [])\n",
    "all_courses = [c for c in canvas.get_courses(enrollment_state=\"active\")\n",
    "               if any(c.name.startswith(p) for p in wanted_prefixes)]\n",
    "\n",
    "print(\"Selected courses:\", [c.name for c in all_courses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a7834b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: Foundations '25 Data Science (domain=technical)\n",
      "Course: Foundations Course (domain=technical)\n",
      "Course: IF '25 Data Science Cohort A (domain=technical)\n",
      "Course: IF '25 NY Career Readiness and Success (domain=career)\n",
      "Built 323 facts\n"
     ]
    }
   ],
   "source": [
    "# 3) Build facts + metas from ALL selected courses\n",
    "facts, metas = [], []\n",
    "for crs in all_courses:\n",
    "    dom = course_domain(crs.name)\n",
    "    print(f\"Course: {crs.name} (domain={dom})\")\n",
    "    for module in crs.get_modules():\n",
    "        for item in module.get_module_items():\n",
    "            t = (item.type or \"\").strip()\n",
    "            if t == \"Page\":\n",
    "                page = crs.get_page(item.page_url)\n",
    "                text = strip_html(getattr(page, \"body\", \"\"))\n",
    "                for chunk in chunk_text(text, max_chars=600):\n",
    "                    facts.append(f\"[{dom}] {crs.name} > {module.name} > {item.title}: {chunk}\")\n",
    "                    metas.append({\n",
    "                        \"domain\": dom,\n",
    "                        \"course_id\": crs.id, \"course_name\": crs.name,\n",
    "                        \"module_id\": module.id, \"module_name\": module.name,\n",
    "                        \"item_title\": item.title, \"type\": \"Page\",\n",
    "                        \"url\": getattr(page, \"html_url\", None)\n",
    "                    })\n",
    "            elif t in (\"ExternalUrl\", \"ExternalTool\"):\n",
    "                facts.append(f\"[{dom}] {crs.name} > {module.name} > {item.title}: external link {getattr(item, 'external_url', '')}\")\n",
    "                metas.append({\n",
    "                    \"domain\": dom, \"course_id\": crs.id, \"course_name\": crs.name,\n",
    "                    \"module_id\": module.id, \"module_name\": module.name,\n",
    "                    \"item_title\": item.title, \"type\": t,\n",
    "                    \"url\": getattr(item, \"external_url\", None)\n",
    "                })\n",
    "            elif t == \"File\":\n",
    "                facts.append(f\"[{dom}] {crs.name} > {module.name} > {item.title} (file)\")\n",
    "                metas.append({\n",
    "                    \"domain\": dom, \"course_id\": crs.id, \"course_name\": crs.name,\n",
    "                    \"module_id\": module.id, \"module_name\": module.name,\n",
    "                    \"item_title\": item.title, \"type\": \"File\", \"file_id\": item.content_id\n",
    "                })\n",
    "            elif t == \"SubHeader\":\n",
    "                continue\n",
    "            else:\n",
    "                facts.append(f\"[{dom}] {crs.name} > {module.name} > {item.title} ({t})\")\n",
    "                metas.append({\n",
    "                    \"domain\": dom, \"course_id\": crs.id, \"course_name\": crs.name,\n",
    "                    \"module_id\": module.id, \"module_name\": module.name,\n",
    "                    \"item_title\": item.title, \"type\": t\n",
    "                })\n",
    "\n",
    "print(f\"Built {len(facts)} facts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3952bff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e51fc3e31e440cadbe3159a673286e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS ntotal: 323\n"
     ]
    }
   ],
   "source": [
    "# 4) Embed â€” use GPU if available, else CPU\n",
    "import torch\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=DEVICE)\n",
    "print(\"model device:\", model.device)\n",
    "\n",
    "# (optional) quick warm-up on GPU\n",
    "if DEVICE == \"cuda\":\n",
    "    _ = model.encode([\"warm up\"], show_progress_bar=False)\n",
    "\n",
    "# pick a sensible batch size per device\n",
    "BATCH = 192 if DEVICE == \"cuda\" else 64\n",
    "\n",
    "emb = model.encode(\n",
    "    facts,\n",
    "    batch_size=BATCH,\n",
    "    normalize_embeddings=True,   # cosine-ready\n",
    "    convert_to_numpy=True,       # returns NumPy on CPU for FAISS\n",
    "    show_progress_bar=True\n",
    ").astype(\"float32\")\n",
    "\n",
    "d = emb.shape[1]\n",
    "index = faiss.IndexFlatIP(d)               # cosine (vectors normalized)\n",
    "index.add(emb)\n",
    "print(\"FAISS ntotal:\", index.ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6896266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Router: choose technical / career / all based on similarity to route descriptions\n",
    "route_emb = {k: model.encode([v], normalize_embeddings=True).astype(\"float32\") for k,v in ROUTE_DESC.items()}\n",
    "\n",
    "def choose_scope(query, margin=0.05):\n",
    "    q = model.encode([query], normalize_embeddings=True).astype(\"float32\")\n",
    "    sims = {k: float((q @ route_emb[k].T)[0,0]) for k in ROUTE_DESC}\n",
    "    best = max(sims, key=sims.get)\n",
    "    # if not clearly better, use 'all'\n",
    "    ordered = sorted(sims.items(), key=lambda x: x[1], reverse=True)\n",
    "    if ordered[0][1] - ordered[1][1] < margin:\n",
    "        return \"all\", sims\n",
    "    return best, sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca57c034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Search with optional scope filter (auto by default)\n",
    "def search(query, k=5, scope=\"auto\"):\n",
    "    if scope == \"auto\":\n",
    "        scope, sims = choose_scope(query)\n",
    "    q = model.encode([query], normalize_embeddings=True).astype(\"float32\")\n",
    "    # pull more then filter by domain\n",
    "    D, I = index.search(q, k*8)\n",
    "    hits = []\n",
    "    for score, idx in zip(D[0], I[0]):\n",
    "        if idx == -1: continue\n",
    "        m = metas[idx]\n",
    "        if scope != \"all\" and m[\"domain\"] != scope:\n",
    "            continue\n",
    "        hits.append({\"score\": float(score), \"fact\": facts[idx], \"meta\": m})\n",
    "        if len(hits) >= k: break\n",
    "    # if not enough in-scope, backfill with any\n",
    "    if len(hits) < k:\n",
    "        for score, idx in zip(D[0], I[0]):\n",
    "            if idx == -1: continue\n",
    "            if any(h[\"meta\"] is metas[idx] for h in hits): continue\n",
    "            hits.append({\"score\": float(score), \"fact\": facts[idx], \"meta\": metas[idx]})\n",
    "            if len(hits) >= k: break\n",
    "    return scope, hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d818042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: Where did we define precision vs. recall?   [scope=technical]\n",
      "  0.382 :: IF '25 Data Science Cohort A > P2W3 (6/23-6/27) Classification Algorithms > ðŸ’» W3D2 (6/24) Logistic Regression Accuracy Metrics (Page)  [https://tkh.instructure.com/courses/172/pages/w3d2-6-slash-24-logistic-regression-accuracy-metrics]\n",
      "  0.306 :: Foundations '25 Data Science > Week 5:  Statistics(Feb. 24th- Feb. 27th) > What is Data Science? (Page)  [https://tkh.instructure.com/courses/165/pages/what-is-data-science]\n",
      "  0.276 :: IF '25 Data Science Cohort A > P2W11 (8/18-8/22) Agents & End of Phase Project > ðŸ’» W11D1 (8/18) Applied LLM Review & AI Agents (Page)  [https://tkh.instructure.com/courses/172/pages/w11d1-8-slash-18-applied-llm-review-and-ai-agents]\n",
      "  0.263 :: IF '25 Data Science Cohort A > P2W9 (8/4-8/8) NLP Foundations & Transformers > ðŸ“š P2W9 Overview & Lesson Plan (Page)  [https://tkh.instructure.com/courses/172/pages/p2w9-overview-and-lesson-plan]\n",
      "\n",
      "Q: tips for a resume and cover letter?   [scope=career]\n",
      "  0.443 :: IF '25 NY Career Readiness and Success > Phase 2 (6/9-8/29) > Homework: Upwardly Global Learning Paths: Tech Market/Resume/Cover Letter (Assignment)\n",
      "  0.426 :: IF '25 NY Career Readiness and Success > Phase 2 (6/9-8/29) > Homework: Draft Resume (Assignment)\n",
      "  0.368 :: IF '25 NY Career Readiness and Success > Phase 2 (6/9-8/29) > Homework: LinkedIn Profile (Assignment)\n",
      "  0.354 :: IF '25 NY Career Readiness and Success > Phase 2 (6/9-8/29) > Homework: Upwardly Global Learning Path: Marketing Yourself (Assignment)\n",
      "\n",
      "Q: What lecture slides did we learn about control flow?   [scope=technical]\n",
      "  0.389 :: Foundations Course > Week 1: Foundations For Success (Jan. 27th-Jan. 30th) > W1D2: Learning How to Learn (Page)  [https://tkh.instructure.com/courses/162/pages/w1d2-learning-how-to-learn]\n",
      "  0.350 :: Foundations Course > Week 2: Charting Your Path (Feb. 3rd- Feb 6th) > W2D3: Track Exploration (Track Mini LessonsÂ Continued) (Page)  [https://tkh.instructure.com/courses/162/pages/w2d3-track-exploration-track-mini-lessons-continued]\n",
      "  0.348 :: Foundations Course > Week 3: Tech Essentials (Feb. 10th- Feb 13th) > Week 3 Overview  (Page)  [https://tkh.instructure.com/courses/162/pages/week-3-overview]\n",
      "  0.339 :: Foundations Course > Week 2: Charting Your Path (Feb. 3rd- Feb 6th) > W2D2: Track Exploration (Track Mini Lessons)Â  (Page)  [https://tkh.instructure.com/courses/162/pages/w2d2-track-exploration-track-mini-lessons]\n"
     ]
    }
   ],
   "source": [
    "# 7) Try it out with some pre-test test-prompts\n",
    "tests = [\n",
    "    \"Where did we define precision vs. recall?\",\n",
    "    \"tips for a resume and cover letter?\",\n",
    "    \"What lecture slides did we learn about control flow?\",\n",
    "  ]\n",
    "for q in tests:\n",
    "    scope, hits = search(q, k=4, scope=\"auto\")\n",
    "    print(f\"\\nQ: {q}   [scope={scope}]\")\n",
    "    if not hits: print(\"  (no hits)\"); continue\n",
    "    for h in hits:\n",
    "        m = h[\"meta\"]\n",
    "        cite = f\"{m['course_name']} > {m['module_name']} > {m['item_title']} ({m['type']})\"\n",
    "        if m.get(\"url\"): cite += f\"  [{m['url']}]\"\n",
    "        print(f\"  {h['score']:.3f} :: {cite}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffaf296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Persist FAISS + metadata to the repo root (SLIDEHUNTER/) ---\n",
    "from pathlib import Path\n",
    "import os, json, faiss\n",
    "\n",
    "# 0) Resolve project base: prefer env var; else step out of notebooks/\n",
    "ENV_BASE = os.getenv(\"SLIDEHUNTER_BASE\") or os.getenv(\"SLIDEHUNT_BASE\")\n",
    "if ENV_BASE:\n",
    "    BASE = Path(ENV_BASE).resolve()\n",
    "else:\n",
    "    here = Path.cwd().resolve()\n",
    "    BASE = here.parent if here.name.lower() == \"notebooks\" else here  # run from repo root if you're inside notebooks/\n",
    "\n",
    "# 1) Paths under the repo\n",
    "STORE_DIR  = BASE / \"data\" / \"faiss\"\n",
    "INDEX_PATH = STORE_DIR / \"canvas.index\"\n",
    "FACTS_PATH = STORE_DIR / \"facts.json\"\n",
    "STORE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2) Save / Load helpers\n",
    "def save_store(index, facts, metas, index_path=INDEX_PATH, facts_path=FACTS_PATH):\n",
    "    faiss.write_index(index, str(index_path))\n",
    "    with open(facts_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"facts\": facts, \"metas\": metas}, f, ensure_ascii=False)\n",
    "    print(\"saved:\", index_path)\n",
    "    print(\"saved:\", facts_path)\n",
    "\n",
    "def load_store(index_path=INDEX_PATH, facts_path=FACTS_PATH):\n",
    "    idx = faiss.read_index(str(index_path))\n",
    "    data = json.load(open(facts_path, \"r\", encoding=\"utf-8\"))\n",
    "    print(\"loaded:\", index_path, \"and\", facts_path)\n",
    "    return idx, data[\"facts\"], data[\"metas\"]\n",
    "\n",
    "# 3) Save right after you build `index`, `facts`, `metas`\n",
    "save_store(index, facts, metas)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
